{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Assignment\n",
    "\n",
    "**Acknowledgements:** The following assignment is based on GeeksforGeeks [tutorials](https://www.geeksforgeeks.org/opencv-python-tutorial/). \n",
    "This assignment is a quick introduction to the vast capabilities of the opencv library. It is highly recommended you also peruse through these tutorials in addition to this.\n",
    "\n",
    "## What is OpenCV?\n",
    "\n",
    "OpenCV is a popular open-source library for both computer vision, machine learning, and image processing used by both industry and academia to solve image processing problems. It can be used in C++, Java and Python (the language of our focus). It can do anything from manipulating images for pre-processing to running machine learning models such as SVM's to identify hand-written letters. Furthermore, this library is highly optimized for numerical operations and uses numpy arrays to represent images.\n",
    "\n",
    "## Configuring OpenCV\n",
    "\n",
    "To install opencv for python, run `pip install opencv-python`. To see other installation options visit these tutorials for [Windows](https://www.geeksforgeeks.org/how-to-install-opencv-for-python-in-windows/), [Linux](https://www.geeksforgeeks.org/how-to-install-opencv-for-python-in-linux/) and, [Anaconda](https://www.geeksforgeeks.org/set-opencv-anaconda-environment/).\n",
    "\n",
    "Once you've installed opencv, run the block below.\n",
    "\n",
    "**Note:** This version of opencv-python is CPU-only by default. It is possible to GPU-accelerate opencv if you have a compatible Nvidia graphics card and build from OpenCV sources. Procedure varies drastically based on numerous factors such as GPU architecture, CUDA and CUDnn versions, and more so it is recommended only if you're seasoned enough with building custom binaries and you have a need to use a GPU-accelerated version of OpenCV. Do your research before attempting to build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading, Writing and Displaying Image Media\n",
    "\n",
    "### ðŸš¨ðŸš¨**WARNING**ðŸš¨ðŸš¨ OPENCV BY DEFAULT REPRESENTS IMAGES AS BGR (AS OPPOSED TO RGB) FOR ALL OPERATIONS. \n",
    "If you're scratching your head as to why an image colourspace appears funky, that's most likely why.\n",
    "\n",
    "### Reading, Writing and Displaying an Image\n",
    "\n",
    "To read in a single image, run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_img = cv2.imread('../.media/apple.jpg') # loads in image as BGR numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV also has a function to show an image called `imshow`, which creates a new window to display your image. Unfortunately Jupyter Notebooks do not support new windows.\n",
    "\n",
    "Instead we will run the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python opencv_helper.py -f read_image -p ../.media/apple.jpg -d True   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which opens a new window showing the picture of our apple.\n",
    "\n",
    "To see what this command does exactly, open opencv_helper.py in the same folder as this jupyter notebook. The relevant lines are as follows\n",
    "\n",
    "```python\n",
    "\n",
    "def show_image(name: str, img): # helper function to show image\n",
    "    cv2.imshow(name, img) # shows image\n",
    "    cv2.waitKey(0) # waitkey function controls time to show image. Will close image either once time expires (number passed is in ms) or use presses key\n",
    "\n",
    "def read_image(name: str, turn_image_on : bool):\n",
    "    img = cv2.imread(name)\n",
    "    \n",
    "    if turn_image_on:\n",
    "        show_image(name, img)\n",
    "```\n",
    "\n",
    "To close the window, press any key\n",
    "\n",
    "Alternatively you can use matplotlib to show the image as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_img = cv2.cvtColor(apple_img, cv2.COLOR_BGR2RGB) #HINT: great way to convert an image between colour spaces!\n",
    "\n",
    "plt.imshow(mat_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the numpy tutorial, let's say we wanted to save our mask of our apple as a .png -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.where(apple_img < 10, 0, 255) #thresholding all pixel values with less than 10 to zero, other wise make it \"white\"\n",
    "mask = mask[:,:,0] | mask[:,:,1] | mask[:,:,2] #2d mask created by oring all channels together\n",
    "mask = np.moveaxis(np.array([mask,mask,mask]), 0, -1)\n",
    "\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to following to save the image,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('../.media/apple_mask.png', mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now see the newly generated `apple_mask.png` under `.media/`! Keep the mask image for now, we will need it later "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading, Writing and Displaying Video\n",
    "\n",
    "The natural next step in learning OpenCV is reading, writing and displaying video. \n",
    "\n",
    "The command below live-streams your webcam. If you want load in your own video file (i.e. .mp4), replace `0` with your own path to the video file. To specify a specific play back frame rate pass `-r <fps number>` or `-fps <fps number>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python opencv_helper.py -f play_video -p 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command above runs the relevant code snippet as follows -\n",
    "\n",
    "```python\n",
    "def play_video(name: str, frame_rate=float):\n",
    "    \n",
    "    waitkey_ms = fps_to_ms(frame_rate)\n",
    "    \n",
    "    if name.isdigit():\n",
    "        cap = cv2.VideoCapture(int(name)) # either capture from webcam\n",
    "    else:                                 # or\n",
    "        cap = cv2.VideoCapture(name)      # capture from specified video\n",
    "        \n",
    "    if not cap.isOpened(): # throws error if capture object isn't open\n",
    "        print(\"Error opening video file\")\n",
    "                \n",
    "    while (cap.isOpened()): # while capture object is open\n",
    "        \n",
    "        ret, frame = cap.read() # ret: if frame is valid, frame: actual image array\n",
    "        if ret == True:\n",
    "            cv2.imshow(name, frame) # show frame\n",
    "            if cv2.waitKey(waitkey_ms) == ord('q'): #quit when 'q' is pressed.\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "```\n",
    "\n",
    "Awesome right? Now let's look at writing a video!\n",
    "\n",
    "To write a video, run the following command,\n",
    "\n",
    "**Note:** If you want to specify where to save your video file, add flag `-s <insert save path and file name>.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python opencv_helper.py -f write_video -p 0 -r 30.0 -d True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV Bitwise Operators\n",
    "\n",
    "OpenCV has numerous useful bitwise operators to help manipulate images. Let's a look at several examples of what this may entail.\n",
    "\n",
    "First create a mask of a 100x100 pixel black square in the middle of a white background the same size as the apple_mask.png. Let's see what happens when we do bitwise and of our two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_image(img):\n",
    "    mat_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "    plt.imshow(mat_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load apple_mask.png as gray scale\n",
    "# HINT: pass cv2.IMREAD_GRAYSCALE into cv2.imread\n",
    "\n",
    "# insert your code here.\n",
    "\n",
    "# create mask based on dimensions of apple_mask.png \n",
    "\n",
    "# insert your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run and show resulting image\n",
    "\n",
    "and_result = cv2.bitwise_and(square_mask, apple_mask, mask=None)\n",
    "plt_image(and_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there's square in the middle of our apple mask!\n",
    "\n",
    "Now create an mask image the same dimensions as the apple_mask except where half the image is white and the other black. Let's what happens when we apply bitwise \"or\" to our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask based on dimensions of apple_mask.png \n",
    "\n",
    "# insert your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run and show resulting image\n",
    "\n",
    "or_result = cv2.bitwise_or(half_mask, apple_mask, mask=None)\n",
    "plt_image(or_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now half our image is white and the other half show the apple partially.\n",
    "\n",
    "What happens if we apply bitwise \"xor\" instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run and show resulting image\n",
    "\n",
    "or_result = cv2.bitwise_xor(half_mask, apple_mask, mask=None)\n",
    "plt_image(or_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also invert our apple mask as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run and show resulting image\n",
    "\n",
    "or_result = cv2.bitwise_not(apple_mask, mask=None)\n",
    "plt_image(or_result)"
   ]
  },
  {
   "attachments": {
    "noise.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAADgCAYAAADG3Yu6AAAELElEQVR4nO3cQW7bQBQFwZlA97+ysjVgi4nYlkiOqraGEe4aP3ieOca4DwAI/hz9AQBc3+3oDwDO535//B8Wc87L/3v8PpcJAJmYAJCJCQCZmACQiQkAmZgAkM3hjxYBiFwmAGRiAkAmJgBkYgJAJiYAZGICQObVYOAttl4G3uLV4GtwmQCQiQkAmZgAkIkJAJmYAJCJCQCZV4OBp+yd+L6C2fB5uEwAyMQEgExMAMjEBIBMTADIxASAzDQY+OZM89+9zIbfy2UCQCYmAGRiAkAmJgBkYgJAJiYAZLejPwA4xgrzX87DZQJAJiYAZGICQCYmAGRiAkAmJgBkYgJAJiYAZGICQCYmAGRiAkAmJgBkYgJAJiYAZGICQCYmAGRiAkAmJgBkYgJAJiYAZGICQHY7+gOAY8w5H/7sfr+/8UtYgcsEgExMAMjEBIBMTADIxASATEwAyEyDgSVtzZu3ZtHs4zIBIBMTADIxASATEwAyMQEgExMAMtNg4BsvCvMslwkAmZgAkIkJAJmYAJCJCQCZmACQmQYDTzEb5icuEwAyMQEgExMAMjEBIBMTADIxASCbYwxbPuC/rT7/3Zo+85jLBIBMTADIxASATEwAyMQEgExMAMi8GgwL25rx7p3A7v291SfFn85lAkAmJgBkYgJAJiYAZGICQCYmAGReDQYOd6bZsFeD93GZAJCJCQCZmACQiQkAmZgAkIkJAJlXgwG++NdM2XT4Zy4TADIxASATEwAyMQEgExMAMjEBIDMNBg63Nbc904vCPOYyASATEwAyMQEgExMAMjEBIBMTADLTYIAnbE2VP/lFYZcJAJmYAJCJCQCZmACQiQkAmZgAkJkGA6fmReFrcJkAkIkJAJmYAJCJCQCZmACQiQkAmWkwcGrmv9fgMgEgExMAMjEBIBMTADIxASATEwCyOcawuwOWc7ZJ8dbrxytwmQCQiQkAmZgAkIkJAJmYAJCJCQCZmACQiQkAmZgAkIkJAJmYAJCJCQCZmACQ3Y7+AIBX2Hql92wvCq/AZQJAJiYAZGICQCYmAGRiAkAmJgBkpsEAb7A1R96aMV+FywSATEwAyMQEgExMAMjEBIBMTADITIMBDrbCK8YuEwAyMQEgExMAMjEBIBMTADIxASAzDQaWtMLc9kpcJgBkYgJAJiYAZGICQCYmAGRiAkBmGsxDW9PKOecbv4SrMMf9XC4TADIxASATEwAyMQEgExMAMjEBIJtjDFu+nUxn38fkFM7NZQJAJiYAZGICQCYmAGRiAkAmJgBkXg1mF1Nd4CuXCQCZmACQiQkAmZgAkIkJAJmYAJCJCQCZJ+g/gL8JAV7NZQJAJiYAZGICQCYmAGRiAkAmJgBknqC/EBNf4KxcJgBkYgJAJiYAZGICQCYmAGRiAkBmGnwAE19gNS4TADIxASD7C5rHarskqfcjAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Image Processing \n",
    "\n",
    "Looking at our apple mask, there some specks that are not apart of our tresholding. \n",
    "\n",
    "![noise.png](attachment:noise.png)\n",
    "\n",
    "Let's get rid of these specks using something called morphological transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line and Object Detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running YOLO with OpenCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
